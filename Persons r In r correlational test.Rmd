---
title: "Pearsons r in R"
author: "Lasse Hansen"
date: "10/8/2019"
output: html_document
---

First i will load the packages necessary:

```{r}
pacman::p_load("Hmisc","ggm","ggplot2","polycor","boot")

install.packages("Rcmdr")
```

```{r}
examData <- read.delim("Exam Anxiety.Dat", header = TRUE)
examData2 <- examData[, c("Exam", "Anxiety", "Revise")]
cor(examData2)
```

The first issue we have is that some of the variables are not numeric (Gender) and others are not meaningful numerically (code). We have two choices here. The first is to make a new dataframe by selecting only the variables of interest) – we discovered how to do this in section 3.9.1. The second is to specify this subset within the cor() command itself. If we choose the first method then we should execute:


The output provides a matrix of the correlation coefficients for the three variables. Each variable is perfectly correlated with itself (obviously) and so r = 1 along the diagonal of the table. 

Exam performance is negatively related to exam anxiety with a Pearson correlation coefficient of r = −.441. This is a reasonably big effect. 

Exam performance is positively related to the amount of time spent revising, with a coefficient of r = .397, which is also a reasonably big effect. 

Finally, exam anxiety appears to be negatively related to the time spent revising, r = −.709, which is a substantial effect size. 

In psychological terms, this all means that as anxiety about an exam increases, the percentage mark obtained in that exam decreases. Conversely, as the amount of time revising increases, the percentage obtained in the exam increases. Finally, as revision time increases, the student’s anxiety about the exam decreases. So there is a complex interrelationship between the three variables.

##Doing the same using rcorr()

Correlation coefficients are effect sizes, so we can interpret these values without really needing to worry about p-values (and as I have tried to drum into you, because p-values are related to sample size, there is a lot to be said for not obsessing about them). However, if you are the type of person who obsesses about p-values, then you can use the rcorr() function instead and p yourself with excitement at the output it produces. First, make sure
you have loaded the Hmisc package by executing:

```{r}
install.packages(Hmisc)
library(Hmisc)
```

Next, we need to convert our dataframe into a matrix using the as.matrix() command. We can include only numeric variables so, just as we did above, we need to select only the numeric variables within the examData dataframe. To do this, execute:

```{r}
examMatrix<-as.matrix(examData[, c("Exam", "Anxiety", "Revise")])
```

Which creates a matrix called examMatrix that contains only the variables Exam, Anxiety, and Revise from the examData dataframe. To get the correlation matrix we simply input this matrix into the rcorr() function:

```{r}
rcorr(examMatrix)
```

The output shows the same correlation matrix as, except rounded to 2 decimal places. In addition, we are given the sample size on which these correlations are based, and also a matrix of p-values that corresponds to the matrix of correlation coefficients above. Exam performance is negatively related to exam anxiety with a Pearson correlation coefficient of r = −.44 and the significance value is less than .001 (it is approximately zero). This signifi- cance value tells us that the probability of getting a correlation coefficient this big in a sample of 103 people if the null hypothesis were true (there was no relationship between these vari- ables) is very low (close to zero in fact). Hence, we can gain confidence that there is a genuine relationship between exam performance and anxiety. Our criterion for significance is usually .05 so we can say that all of the correlation coefficients are significant.

##Looking at the confidence intervals 

It can also be very useful to look at confidence intervals for correlation coefficients. Sadly, we have to do this one at a time (we can’t do it for a whole dataframe or matrix). Let’s look at the correlation between exam performance (Exam) and exam anxiety (Anxiety). We can compute the confidence interval using cor.test() by executing:

```{r}

cor.test(examData$Anxiety, examData$Exam)
```
Note that we have specified only the variables because by default this function produces Pearson’s r and a 95% confidence interval. Output 6.3 shows the resulting output; it reiter- ates that the Pearson correlation between exam performance and anxiety was –.441, but tells us that this was highly significantly different from zero, t(101) = –4.94, p < .001. Most important, the 95% confidence ranged from –.585 to – .271, which does not cross zero. This tells us that in all likelihood, the population or actual value of the correlation is negative, so we can be pretty content that exam anxiety and exam performance are, in reality, negatively related.


